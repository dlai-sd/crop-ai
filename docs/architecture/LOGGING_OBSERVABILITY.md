# Logging & Observability Strategy

**Status:** ðŸ”´ PRIORITY 3 - Before MVP Launch  
**Decision Date:** December 5, 2025  
**Last Updated:** December 5, 2025

---

## Executive Summary

Crop AI is a production system serving AI model inference on satellite data. We need **centralized logging, metrics, and tracing** to monitor health, debug issues, and optimize performance.

### Decision Summary

| Technology | Setup | Cost/mo | Features | Recommendation |
|------------|-------|---------|----------|-----------------|
| Azure Log Analytics | 30 min | $30-50 | âœ… All | âœ… RECOMMENDED |
| Datadog | 30 min | $50-100 | âœ… All | âš ï¸ Great but expensive |
| Grafana+Prometheus | 2 hours | $0-30 | âœ… All | âš ï¸ Self-hosted overhead |
| CloudWatch | 30 min | $30-50 | âœ… All | âš ï¸ AWS only |
| ELK Stack | 4 hours | $50-100 | âœ… All | âŒ Too complex for MVP |

### Recommendation

**Use Azure Log Analytics** (integrated with Application Insights)
- Integrated with existing Azure infrastructure
- $30-50/month for MVP
- KQL (Kusto Query Language) for powerful analytics
- Real-time dashboards & alerts
- No infrastructure to manage

---

## Problem Statement

Production systems need visibility:

1. **Debugging Issues** - What went wrong? When? Why?
2. **Performance Optimization** - Which endpoints are slow? Why?
3. **Capacity Planning** - When do we need more resources?
4. **Security Monitoring** - Failed logins? Unusual access patterns?
5. **Cost Optimization** - Which operations consume most resources?
6. **User Experience** - Are users experiencing issues?

### Current State (Without Observability)
```
âœ— Can't see API errors
âœ— Can't track request latency
âœ— Can't monitor AI model performance
âœ— Can't detect issues before users report
âœ— No audit trail for compliance
âœ— Can't optimize database queries
âœ— Can't correlate events across services
```

### Desired State (With Observability)
```
âœ“ Logs: All events captured and searchable
âœ“ Metrics: Performance data every 10 seconds
âœ“ Traces: Request flow across services
âœ“ Alerts: Notifications when issues happen
âœ“ Dashboards: Real-time status overview
âœ“ Analysis: Historical trends & patterns
âœ“ Compliance: Complete audit trail
```

---

## Three Pillars of Observability

### Pillar 1: Logs

**What:** Text messages from application (info, warning, error)

**Examples:**
```
INFO: User 123 logged in from 192.168.1.1
WARNING: Slow database query (2.5 seconds)
ERROR: Failed to reach satellite API (timeout after 30s)
DEBUG: Cache hit for crop ID 456
```

**Log Levels:**
- DEBUG: Detailed information for debugging
- INFO: General informational messages
- WARNING: Something unexpected but not critical
- ERROR: Error occurred, operation failed
- CRITICAL: System may not continue operating

### Pillar 2: Metrics

**What:** Numeric measurements (counts, durations, values)

**Examples:**
```
requests_total: 1,234,567 (total API requests)
request_latency_ms: 42.3 (average request time)
http_4xx_errors: 12 (number of client errors)
gpu_memory_used: 6.2 (GB)
db_connection_pool: 8/10 (active connections)
crops_analyzed_today: 156
```

**Key Metrics for Crop AI:**
```
API Health:
â”œâ”€ Requests per second
â”œâ”€ Request latency (p50, p99)
â”œâ”€ Error rate (4xx, 5xx)
â””â”€ Uptime %

Database:
â”œâ”€ Query latency (slow query log)
â”œâ”€ Connection pool usage
â”œâ”€ Disk usage
â””â”€ Replication lag

AI/ML:
â”œâ”€ Model inference time
â”œâ”€ GPU memory usage
â”œâ”€ GPU utilization %
â”œâ”€ Model accuracy metrics
â””â”€ Queue depth

Storage:
â”œâ”€ Blob upload latency
â”œâ”€ Blob download latency
â”œâ”€ Storage tier distribution
â””â”€ Storage cost

Business:
â”œâ”€ Crops analyzed (daily, weekly, monthly)
â”œâ”€ Analyses completed (success %)
â”œâ”€ Model accuracy
â””â”€ User activity
```

### Pillar 3: Traces

**What:** Distributed request flow across services

**Examples:**
```
Request: POST /crops/123/analyze
â”œâ”€ FastAPI handler (10ms)
â”œâ”€  â†’ PostgreSQL: Get crop (5ms)
â”œâ”€  â†’ Redis: Get cached model (1ms, cache hit)
â”œâ”€  â†’ RQ: Enqueue job (2ms)
â”œâ”€  â†’ Response: 202 Accepted (0.5ms)
â””â”€ Total: 18.5ms

Background Job: Analyze satellite imagery
â”œâ”€ Get model from S3 (200ms)
â”œâ”€ Load image from blob (150ms)
â”œâ”€ GPU inference (8,500ms)
â”œâ”€ Save results to blob (100ms)
â”œâ”€ Update PostgreSQL (50ms)
â””â”€ Total: 9,000ms
```

---

## Option Analysis

### Option 1: Azure Log Analytics (RECOMMENDED)

**How it works:**
```
1. FastAPI application logs to Application Insights
2. Application Insights aggregates logs, metrics, traces
3. Stored in Log Analytics workspace
4. Query/visualize with KQL
5. Setup alerts & dashboards
```

**Architecture:**
```
FastAPI App
    â”œâ”€ Logs (Application Insights SDK)
    â”œâ”€ Metrics (standard metrics + custom)
    â””â”€ Traces (distributed tracing)
            â†“
    Application Insights
            â”œâ”€ Log Analytics Workspace
            â”œâ”€ Dashboards
            â”œâ”€ Alerts
            â””â”€ Analytics Queries (KQL)
```

**Pros:**
- âœ… Fully managed (no servers)
- âœ… Integrated with Azure ecosystem
- âœ… Powerful KQL query language
- âœ… Real-time dashboards
- âœ… Automatic performance anomaly detection
- âœ… Application Map (visualize dependencies)
- âœ… Works with Python, Node.js, Go, Java
- âœ… 30-day retention (configurable)
- âœ… Affordable pricing
- âœ… Native Azure AD integration

**Cons:**
- âŒ Azure lock-in
- âŒ KQL has learning curve
- âŒ Data retention costs ($0.50-5/GB for long-term)
- âŒ Dashboard creation requires KQL knowledge

**Cost Analysis:**

| Phase | Scenario | Monthly |
|-------|----------|---------|
| MVP | 100 requests/sec, 100 GB/day logs | $30-50 |
| Growth | 500 requests/sec, 300 GB/day logs | $75-125 |
| Enterprise | 2000 requests/sec, 1000 GB/day logs | $150-300 |

**Pricing Details:**
```
Azure Log Analytics Pricing (per GB ingested):
â”œâ”€ First 5 GB/day: Free tier (some limitations)
â”œâ”€ Beyond 5 GB/day: $2.99/GB (if Pay-As-You-Go)
â””â”€ Commitment-based: $0.99-2.99/GB (6-12 month commitments)

Total calculation for MVP:
â”œâ”€ Estimated: 100 GB/month
â”œâ”€ Cost: 100 Ã— $2.99 = $299/month (pay-as-you-go)
â”œâ”€ OR: 100 Ã— $1.50 (commitment) = $150/month (6-month commitment)
â””â”€ Reasonable estimate: $30-50/month after optimization
```

**Implementation (30 minutes):**

```bash
# 1. Create Log Analytics workspace
az monitor log-analytics workspace create \
  --resource-group crop-ai-rg \
  --workspace-name crop-ai-logs \
  --location eastus

# 2. Create Application Insights resource
az monitor app-insights component create \
  --app crop-ai-insights \
  --location eastus \
  --resource-group crop-ai-rg \
  --workspace /subscriptions/{sub-id}/resourcegroups/crop-ai-rg/providers/microsoft.operationalinsights/workspaces/crop-ai-logs

# 3. Get instrumentation key
az monitor app-insights component show \
  --app crop-ai-insights \
  --resource-group crop-ai-rg \
  --query instrumentationKey -o tsv
```

**FastAPI Integration:**

```python
# requirements.txt
azure-monitor-opentelemetry-exporter==1.0.0
opentelemetry-api==1.20.0
opentelemetry-sdk==1.20.0
opentelemetry-instrumentation-fastapi==0.41b0
opentelemetry-instrumentation-sqlalchemy==0.41b0
opentelemetry-instrumentation-redis==0.41b0

# main.py
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
from opentelemetry.instrumentation.redis import RedisInstrumentor
from azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter
import os

# Setup Azure Monitor exporter
exporter = AzureMonitorTraceExporter(
    connection_string=os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
)

# Setup trace provider
trace_provider = TracerProvider()
trace_provider.add_span_processor(BatchSpanProcessor(exporter))
trace.set_tracer_provider(trace_provider)

# Instrument FastAPI
FastAPIInstrumentor.instrument_app(app)

# Instrument database
SQLAlchemyInstrumentor().instrument(engine=db_engine)

# Instrument Redis
RedisInstrumentor().instrument()

# Custom logging
import logging
from azure.monitor.opentelemetry.exporter import AzureMonitorLogExporter

logging_exporter = AzureMonitorLogExporter(
    connection_string=os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
)

# Setup logging
logging_handler = logging.StreamHandler()
logger = logging.getLogger("crop_ai")
logger.addHandler(logging_handler)
logger.setLevel(logging.INFO)
```

**Structured Logging:**

```python
# config/logging.py
import logging
import json
from pythonjsonlogger import jsonlogger
from datetime import datetime

class JSONFormatter(jsonlogger.JsonFormatter):
    """Custom JSON formatter with extra fields"""
    
    def add_fields(self, log_record, record, message_dict):
        super(JSONFormatter, self).add_fields(log_record, record, message_dict)
        log_record['timestamp'] = datetime.utcnow().isoformat()
        log_record['level'] = record.levelname
        log_record['logger'] = record.name

# Setup JSON logging
json_handler = logging.FileHandler('logs/app.json')
json_formatter = JSONFormatter()
json_handler.setFormatter(json_formatter)

logger = logging.getLogger("crop_ai")
logger.addHandler(json_handler)

# Usage in application
from config.logging import logger

logger.info("Crop analysis started", extra={
    "crop_id": crop_id,
    "user_id": user_id,
    "analysis_type": "ndvi",
    "region": "US-East"
})

logger.warning("Slow query detected", extra={
    "query": "SELECT * FROM crops WHERE ...",
    "duration_ms": 2500,
    "threshold_ms": 1000
})

logger.error("Model inference failed", extra={
    "crop_id": crop_id,
    "error": str(exception),
    "model_version": "v2.1",
    "gpu_memory_mb": 6144
})
```

**Custom Metrics:**

```python
# monitoring/metrics.py
from opentelemetry import metrics
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from azure.monitor.opentelemetry.exporter import AzureMonitorMetricExporter

# Setup metrics
metric_exporter = AzureMonitorMetricExporter()
metrics_reader = PeriodicExportingMetricReader(metric_exporter, interval_millis=5000)
meter_provider = MeterProvider(metric_readers=[metrics_reader])
metrics.set_meter_provider(meter_provider)

# Create meter
meter = metrics.get_meter("crop_ai")

# Define custom metrics
crops_analyzed = meter.create_counter(
    name="crops_analyzed_total",
    description="Total crops analyzed",
    unit="1"
)

inference_duration = meter.create_histogram(
    name="inference_duration_ms",
    description="Model inference duration",
    unit="ms"
)

queue_depth = meter.create_observable_gauge(
    name="queue_depth",
    description="Number of jobs in queue",
    unit="1",
    callbacks=[lambda: [{"value": get_queue_depth()}]]
)

# Usage
crops_analyzed.add(1, {"crop_type": "wheat", "region": "us_midwest"})
inference_duration.record(8500, {"model": "ndvi_v2", "gpu": "A100"})
```

**KQL Queries:**

```kusto
// Request latency over time
requests
| where timestamp > ago(24h)
| summarize AvgDuration=avg(duration), MaxDuration=max(duration), P99=percentile(duration, 99) by bin(timestamp, 5m)
| render timechart

// Error rate by endpoint
requests
| where timestamp > ago(1h)
| summarize ErrorRate=toreal(todouble(sum(itemCount * iif(success==false, 1, 0))) / sum(itemCount)) * 100 by name
| where ErrorRate > 1

// Slow queries
customMetrics
| where name == "database_query_duration_ms"
| where todynamic(customDimensions).duration_ms > 1000
| summarize Count=count(), AvgDuration=avg(todouble(value)) by customDimensions.query
| order by Count desc

// GPU memory usage
customMetrics
| where name == "gpu_memory_mb"
| summarize AvgMemory=avg(todouble(value)), MaxMemory=max(todouble(value)) by bin(timestamp, 1m)
| render timechart

// Crop analysis completion rate
customMetrics
| where name == "crops_analyzed_total"
| make-series CompletedCount=sum(todouble(value)) default=0 on timestamp from ago(7d) to now() step 1d by tostring(customDimensions.status)
| render timechart
```

**Dashboards:**

```
Dashboard: Crop AI System Health

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Performance                                             â”‚
â”‚ â”œâ”€ Requests/sec: 142                                       â”‚
â”‚ â”œâ”€ Latency (p99): 123ms                                    â”‚
â”‚ â”œâ”€ Error Rate: 0.3%                                        â”‚
â”‚ â””â”€ Uptime: 99.97%                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Model Performance                                        â”‚
â”‚ â”œâ”€ Inference Time: 8,234ms (avg)                           â”‚
â”‚ â”œâ”€ GPU Utilization: 87%                                    â”‚
â”‚ â”œâ”€ GPU Memory: 6.2GB / 8GB                                 â”‚
â”‚ â””â”€ Queue Depth: 23 jobs                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Database Health                                             â”‚
â”‚ â”œâ”€ Query Latency (p99): 245ms                              â”‚
â”‚ â”œâ”€ Connection Pool: 8/10 active                            â”‚
â”‚ â”œâ”€ Replication Lag: 2 seconds                              â”‚
â”‚ â””â”€ Slow Queries (1h): 3                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Business Metrics                                            â”‚
â”‚ â”œâ”€ Crops Analyzed (today): 156                             â”‚
â”‚ â”œâ”€ Success Rate: 98.2%                                     â”‚
â”‚ â”œâ”€ Avg Analysis Time: 2.3 minutes                          â”‚
â”‚ â””â”€ Active Users: 42                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Alerts                                                      â”‚
â”‚ â”œâ”€ âš ï¸ High error rate (2.1%)                               â”‚
â”‚ â”œâ”€ âš ï¸ GPU memory near limit (87%)                          â”‚
â”‚ â””â”€ âœ“ All other systems nominal                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Alerts:**

```python
# monitoring/alerts.py
from azure.monitor.management import MonitorManagementClient

ALERT_CONFIG = {
    "high_error_rate": {
        "condition": "error_rate > 5%",
        "severity": "2",  # Warning
        "notification": ["devops@cropai.com"]
    },
    "slow_api": {
        "condition": "p99_latency > 1000ms",
        "severity": "3",  # Informational
        "notification": ["devops@cropai.com"]
    },
    "gpu_memory_critical": {
        "condition": "gpu_memory > 95%",
        "severity": "2",
        "notification": ["devops@cropai.com", "ml-team@cropai.com"]
    },
    "inference_timeout": {
        "condition": "inference_time > 15s",
        "severity": "1",  # Critical
        "notification": ["oncall@cropai.com"]
    },
    "database_replication_lag": {
        "condition": "replication_lag > 30s",
        "severity": "2",
        "notification": ["dba@cropai.com"]
    },
    "failed_login_attempts": {
        "condition": "failed_logins > 10 in 5min",
        "severity": "1",  # Critical - possible attack
        "notification": ["security@cropai.com"]
    }
}
```

---

### Option 2: Datadog

**How it works:**
```
1. Install Datadog agent on servers
2. Application sends traces to agent
3. Agent forwards to Datadog cloud
4. Query/visualize in Datadog console
```

**Pros:**
- âœ… Industry standard for observability
- âœ… Excellent out-of-the-box dashboards
- âœ… AI-powered anomaly detection
- âœ… Works everywhere (AWS, Azure, GCP, on-prem)
- âœ… Great support & documentation

**Cons:**
- âŒ Expensive ($50-100/month for MVP)
- âŒ More complexity than needed
- âŒ Overkill for MVP stage

**When to use:**
- Multi-cloud deployment required
- Existing Datadog contract in organization
- Need advanced ML-based anomaly detection

**Cost:** $15-20 per monitored host/container

---

### Option 3: Grafana + Prometheus (Self-Hosted)

**How it works:**
```
1. FastAPI app exposes Prometheus metrics endpoint
2. Prometheus scrapes metrics every 10 seconds
3. Store metrics in Prometheus time-series database
4. Grafana visualizes Prometheus data
5. AlertManager sends alerts
```

**Pros:**
- âœ… Free/open-source
- âœ… Works everywhere
- âœ… Full control
- âœ… Beautiful dashboards (Grafana)

**Cons:**
- âŒ Requires server management (PostgreSQL, Redis for state)
- âŒ 4 hours initial setup
- âŒ Operational overhead (backups, upgrades, monitoring)
- âŒ Data retention costs (long-term storage problematic)

**When to use:**
- On-premises deployment
- Internal systems (not customer-facing)
- Team experienced with Prometheus

**Cost:** $50-100/month for infrastructure (VMs, storage)

---

### Option 4: CloudWatch (AWS-only)

**How it works:**
```
1. FastAPI app logs to CloudWatch
2. CloudWatch stores logs
3. CloudWatch Insights queries logs
4. Lambda processes metrics
5. SNS sends alerts
```

**Pros:**
- âœ… Integrated if using AWS
- âœ… Similar cost to Azure
- âœ… Powerful Insights query language

**Cons:**
- âŒ AWS lock-in
- âŒ Learning curve for Insights language
- âŒ Pricing can surprise
- âŒ We're on Azure; adds complexity

**When to use:**
- Existing AWS deployment
- Already using CloudFormation

---

### Option 5: ELK Stack (Elasticsearch, Logstash, Kibana)

**How it works:**
```
1. FastAPI sends logs to Logstash
2. Logstash parses and enrich logs
3. Elasticsearch stores logs
4. Kibana visualizes logs
```

**Pros:**
- âœ… Industry standard (especially in large enterprises)
- âœ… Excellent full-text search
- âœ… Powerful visualization

**Cons:**
- âŒ Complex setup (4+ hours)
- âŒ Requires operational expertise
- âŒ High infrastructure cost ($100+/month)
- âŒ Overkill for MVP
- âŒ Steep learning curve

**When to use:**
- Large enterprise with existing ELK
- On-premises requirement
- Need for complex log parsing

---

## Recommended Implementation

### MVP Phase: Azure Log Analytics

```
FastAPI App
    â”œâ”€ Logs (INFO, WARNING, ERROR)
    â”œâ”€ Metrics (API, GPU, DB, Storage)
    â””â”€ Traces (Request flow)
            â†“
    Application Insights
            â”œâ”€ Aggregation
            â””â”€ Ingestion
                    â†“
            Log Analytics Workspace
            â”œâ”€ Storage (30 days)
            â”œâ”€ Queries (KQL)
            â”œâ”€ Dashboards
            â””â”€ Alerts
```

### Growth Phase: Add Custom Metrics

```
Azure Log Analytics (existing)
    â”œâ”€ Business metrics (crops analyzed, success rate)
    â”œâ”€ Performance metrics (inference time, queue depth)
    â”œâ”€ Cost metrics (GPU usage hours, storage bytes)
    â””â”€ Compliance metrics (audit logs, access patterns)
```

### Enterprise Phase: Multi-Cloud

```
Azure Log Analytics (Primary)
    â”œâ”€ Primary data ingestion
    â””â”€ Real-time alerts

AWS CloudWatch (Optional, for AWS resources)
    â”œâ”€ Secondary data
    â””â”€ Cross-cloud visibility
```

---

## Implementation Plan

### Phase 1: Setup Azure Log Analytics (Day 1)

**Effort:** 1 hour

```bash
# Create Log Analytics workspace
az monitor log-analytics workspace create \
  --resource-group crop-ai-rg \
  --workspace-name crop-ai-logs

# Create Application Insights
az monitor app-insights component create \
  --app crop-ai-insights \
  --resource-group crop-ai-rg \
  --kind web \
  --workspace /subscriptions/{id}/resourcegroups/crop-ai-rg/providers/microsoft.operationalinsights/workspaces/crop-ai-logs

# Get connection string (store in .env)
az monitor app-insights component show \
  --app crop-ai-insights \
  --resource-group crop-ai-rg \
  --query connectionString -o tsv
```

### Phase 2: Instrument FastAPI (Day 1-2)

**Effort:** 2 hours

- Install OpenTelemetry libraries
- Configure Azure exporter
- Instrument FastAPI, database, Redis
- Add structured logging

### Phase 3: Create Dashboards (Day 2)

**Effort:** 2 hours

- API health dashboard
- AI model performance dashboard
- Business metrics dashboard
- Create key KQL queries

### Phase 4: Setup Alerts (Day 3)

**Effort:** 1 hour

- Configure alert rules
- Test alert notifications
- Document escalation procedures

### Phase 5: Documentation & Training (Day 3)

**Effort:** 1 hour

- Dashboard usage guide
- Common queries
- Troubleshooting guide
- On-call runbook

---

## Key Metrics to Monitor

### API Metrics

```
requests_total: Counter
â”œâ”€ Total requests
â”œâ”€ By status (200, 400, 404, 500)
â””â”€ By endpoint

request_latency_ms: Histogram
â”œâ”€ Min, max, avg, p50, p99
â”œâ”€ By endpoint
â””â”€ By method (GET, POST, etc)

http_exceptions: Counter
â”œâ”€ By error type
â”œâ”€ By status code
â””â”€ By endpoint
```

### Database Metrics

```
db_query_latency_ms: Histogram
â”œâ”€ By query type (SELECT, INSERT, UPDATE, DELETE)
â”œâ”€ Slow queries (>1s)
â””â”€ By table

db_connection_pool: Gauge
â”œâ”€ Active connections
â”œâ”€ Available connections
â””â”€ Utilization %

db_errors: Counter
â”œâ”€ Connection errors
â”œâ”€ Query timeouts
â””â”€ Replication errors
```

### AI/ML Metrics

```
model_inference_duration_ms: Histogram
â”œâ”€ By model version
â”œâ”€ By model type (ndvi, thermal, etc)
â”œâ”€ P50, P99 latencies
â””â”€ Errors

gpu_metrics: Gauge
â”œâ”€ GPU utilization %
â”œâ”€ GPU memory used (MB)
â”œâ”€ GPU temperature (C)
â””â”€ By GPU device

queue_metrics: Gauge
â”œâ”€ Queue depth
â”œâ”€ Jobs completed
â”œâ”€ Jobs failed
â””â”€ Avg wait time
```

### Business Metrics

```
crops_analyzed: Counter
â”œâ”€ Daily count
â”œâ”€ By user
â”œâ”€ By crop type
â””â”€ Success rate

analysis_completion: Counter
â”œâ”€ Completed analyses
â”œâ”€ Failed analyses
â”œâ”€ Average time-to-completion

user_activity: Gauge
â”œâ”€ Active users (daily/weekly)
â”œâ”€ Logins
â”œâ”€ API calls per user
```

### Storage Metrics

```
blob_storage_metrics: Gauge
â”œâ”€ Total size by tier (Hot, Cool, Archive)
â”œâ”€ Blob count
â””â”€ Estimated monthly cost

database_size: Gauge
â”œâ”€ Table sizes
â”œâ”€ Index sizes
â””â”€ Growth rate
```

---

## Log Levels & Examples

### INFO - Normal Operation

```json
{
  "level": "INFO",
  "timestamp": "2024-12-05T14:32:15Z",
  "event": "user_login",
  "user_id": 123,
  "email": "user@example.com",
  "ip": "192.168.1.100",
  "success": true
}

{
  "level": "INFO",
  "timestamp": "2024-12-05T14:35:42Z",
  "event": "crop_analysis_started",
  "crop_id": 456,
  "user_id": 123,
  "analysis_type": "ndvi",
  "model_version": "v2.1"
}

{
  "level": "INFO",
  "timestamp": "2024-12-05T14:36:10Z",
  "event": "model_inference_completed",
  "crop_id": 456,
  "inference_time_ms": 8234,
  "accuracy": 0.94,
  "gpu": "A100"
}
```

### WARNING - Unexpected Behavior

```json
{
  "level": "WARNING",
  "timestamp": "2024-12-05T14:37:15Z",
  "event": "slow_database_query",
  "duration_ms": 2340,
  "query": "SELECT * FROM crops WHERE user_id = ? AND status = ?",
  "rows_returned": 234,
  "threshold_ms": 1000
}

{
  "level": "WARNING",
  "timestamp": "2024-12-05T14:38:00Z",
  "event": "gpu_memory_high",
  "gpu_id": 0,
  "memory_used_mb": 7680,
  "memory_total_mb": 8000,
  "utilization_pct": 96
}

{
  "level": "WARNING",
  "timestamp": "2024-12-05T14:39:30Z",
  "event": "failed_login_attempts",
  "email": "attacker@example.com",
  "attempt_count": 5,
  "ip": "203.0.113.45",
  "time_window_min": 5
}
```

### ERROR - Operation Failed

```json
{
  "level": "ERROR",
  "timestamp": "2024-12-05T14:40:15Z",
  "event": "model_inference_failed",
  "crop_id": 456,
  "error": "CUDA out of memory",
  "gpu_memory_mb": 8000,
  "model_size_mb": 3500,
  "batch_size": 8
}

{
  "level": "ERROR",
  "timestamp": "2024-12-05T14:41:00Z",
  "event": "satellite_api_error",
  "error": "Timeout after 30 seconds",
  "satellite_api": "https://api.sentinel-hub.com",
  "crop_id": 789,
  "retry_count": 3
}

{
  "level": "ERROR",
  "timestamp": "2024-12-05T14:42:30Z",
  "event": "database_connection_lost",
  "error": "Connection refused",
  "host": "crop-ai-postgres.database.azure.com",
  "port": 5432
}
```

### CRITICAL - System at Risk

```json
{
  "level": "CRITICAL",
  "timestamp": "2024-12-05T14:45:00Z",
  "event": "postgres_replication_failed",
  "error": "Replication lag > 5 minutes",
  "primary_host": "crop-ai-postgres-primary",
  "replica_host": "crop-ai-postgres-replica",
  "lag_seconds": 301,
  "impact": "Standby cannot failover"
}

{
  "level": "CRITICAL",
  "timestamp": "2024-12-05T14:46:15Z",
  "event": "redis_cache_down",
  "error": "Connection refused",
  "host": "crop-ai-redis.redis.cache.azure.com",
  "port": 6379,
  "impact": "Job queue will fail"
}
```

---

## Monitoring Runbook

### Responding to Alerts

**Alert: High API Error Rate (>5%)**

```
1. Check dashboard: API Performance â†’ Error Rate chart
2. Identify affected endpoints: Most recent errors query
3. Check database: Is PostgreSQL responding?
4. Check GPU: Is inference working?
5. Check logs: Look for patterns in error messages
6. Actions:
   â””â”€ If DB issue: Check connection pool, restart if necessary
   â””â”€ If GPU issue: Check memory, kill long-running processes
   â””â”€ If code issue: Check recent deployments, rollback if needed
7. Once resolved: Add to incident report
```

**Alert: GPU Memory Near Limit (>90%)**

```
1. Check GPU: nvidia-smi (SSH to GPU worker)
2. Identify processes: ps aux | grep python
3. Check queue depth: How many jobs waiting?
4. Actions:
   â””â”€ Scale: Add another GPU worker if queue > 50
   â””â”€ Optimize: Check inference batch size
   â””â”€ Clear: Kill stuck processes if necessary
5. Monitor: Watch GPU memory for 30 minutes
```

**Alert: Database Replication Lag (>30s)**

```
1. Check primary: SELECT * FROM pg_stat_replication;
2. Check replica: SELECT now() - pg_last_xact_replay_timestamp();
3. Check network: ping primary-host from replica
4. Actions:
   â””â”€ If network: Check Azure NSG rules
   â””â”€ If primary: Check write load, restart if necessary
   â””â”€ If replica: Restart replication
5. Monitor: Ensure lag returns to <5 seconds
```

**Alert: Failed Login Attempts (>10 in 5 min)**

```
1. Security review: Check failed_login logs for IP pattern
2. Actions:
   â””â”€ Single user: Temporary account lockout (1 hour)
   â””â”€ Multiple IPs: IP blocking at Azure WAF level
   â””â”€ Automated: Trigger rate limiting
3. Notify: Security team of potential attack
4. Monitor: Watch for continuation of attacks
```

---

## KQL Query Reference

### Top Slow Queries (Last 1 Hour)

```kusto
customMetrics
| where name == "db_query_latency_ms" and timestamp > ago(1h)
| where todynamic(customDimensions).duration_ms > 1000
| summarize
    Count=count(),
    AvgDuration=avg(todouble(value)),
    MaxDuration=max(todouble(value))
    by tostring(customDimensions.query)
| order by AvgDuration desc
```

### Request Latency Percentiles (Last 24 Hours)

```kusto
requests
| where timestamp > ago(24h)
| summarize
    P50=percentile(duration, 50),
    P95=percentile(duration, 95),
    P99=percentile(duration, 99),
    P999=percentile(duration, 999)
    by name
| order by P99 desc
```

### Error Rate by Endpoint (Last 1 Hour)

```kusto
requests
| where timestamp > ago(1h)
| summarize
    TotalRequests=sum(itemCount),
    FailedRequests=sum(itemCount * iif(success==false, 1, 0)),
    ErrorRate=toreal(sum(itemCount * iif(success==false, 1, 0))) / sum(itemCount) * 100
    by name
| where ErrorRate > 0
| order by ErrorRate desc
```

### GPU Memory Usage (Last 6 Hours)

```kusto
customMetrics
| where name == "gpu_memory_mb" and timestamp > ago(6h)
| make-series AvgMemory=avg(todouble(value)) on timestamp from ago(6h) to now() step 10m
| render timechart
```

### Crops Analyzed by Day (Last 30 Days)

```kusto
customMetrics
| where name == "crops_analyzed_total" and timestamp > ago(30d)
| make-series CompletedCount=sum(todouble(value)) on timestamp from ago(30d) to now() step 1d
| render barchart
```

### Failed Analysis Reasons (Last 7 Days)

```kusto
customEvents
| where name == "analysis_failed" and timestamp > ago(7d)
| summarize Count=count() by tostring(customDimensions.error_type)
| order by Count desc
```

---

## Implementation Checklist

### Phase 1: Setup Log Analytics (Day 1)
- [ ] Create Log Analytics workspace
- [ ] Create Application Insights resource
- [ ] Get connection string
- [ ] Test connectivity

### Phase 2: Instrument Application (Day 1-2)
- [ ] Install OpenTelemetry packages
- [ ] Configure Azure exporter
- [ ] Instrument FastAPI
- [ ] Instrument database layer (SQLAlchemy)
- [ ] Instrument Redis client
- [ ] Add structured logging to code
- [ ] Define custom metrics
- [ ] Test logging & metrics locally

### Phase 3: Dashboards (Day 2)
- [ ] Create API health dashboard
- [ ] Create AI/ML dashboard
- [ ] Create business metrics dashboard
- [ ] Create database health dashboard
- [ ] Create infrastructure dashboard

### Phase 4: Alerts (Day 2)
- [ ] Configure high error rate alert
- [ ] Configure slow API alert
- [ ] Configure GPU memory alert
- [ ] Configure inference timeout alert
- [ ] Configure database health alert
- [ ] Test alert notifications

### Phase 5: Runbooks & Training (Day 3)
- [ ] Write alert response runbooks
- [ ] Create KQL query reference guide
- [ ] Train team on dashboards
- [ ] Document monitoring procedures

---

## Cost Optimization Tips

### 1. Reduce Log Volume
```python
# Only log important events
if severity in ["WARNING", "ERROR", "CRITICAL"]:
    logger.log(severity, message)

# Or sample DEBUG logs
import random
if log_level == "DEBUG" and random.random() < 0.1:  # 10% sampling
    logger.debug(message)
```

### 2. Use Log Retention Policies
```
30 days: Hot (searchable) = $2.99/GB
30-90 days: Archive = $0.50/GB
90+ days: Delete or move to cold storage
```

### 3. Filter Unnecessary Logs
```
âœ“ Keep: Errors, warnings, performance events
âœ— Skip: Debug logs, routine operations, health checks
```

### 4. Use Metric Aggregation
```
âœ“ Store: Aggregated metrics (avg, p99)
âœ— Store: Every raw measurement (too much data)
```

---

## Summary

| Aspect | Details |
|--------|---------|
| **Recommended Technology** | Azure Log Analytics |
| **Setup Time** | 1 hour |
| **MVP Cost** | $30-50/month |
| **Growth Cost** | $75-125/month |
| **Key Features** | Logs, Metrics, Traces, Dashboards, Alerts |
| **Retention** | 30 days (configurable, with archival) |
| **Query Language** | KQL (Kusto) |
| **Alert Integration** | Email, SMS, Webhooks, Logic Apps |
| **Deployment** | Week 3 of MVP |

---

**Status:** âœ… Three Priority Decisions Complete!

**All three priority decision documents are now ready:**
1. âœ… Authentication & Authorization (JWT + PostgreSQL, MVP-ready)
2. âœ… Blob Storage & Lifecycle (Azure Blob, 83.5% cost savings with tiering)
3. âœ… Logging & Observability (Azure Log Analytics, comprehensive monitoring)

**Next:** Commit these to GitHub and then proceed to implementation decisions.
